# HuggingFace, LoRA with Distributed SageMaker

## MAIN OBJECTIVE:
- To test DISTRIBUTED implementation of LoRA training of HiggingFace's LLM models with Distributed SageMaker
  - Notebook: sagemaker-notebook-LORA.ipynb
  - Steps Review & Findings: In the notebook
  - Status: SUCCESFUL 

## SECONDARY OBJECTIVE:
- To test Distributed Model Parallel Options @ AWS SageMaker
  - Notebook: SM Distributed Training - DDP & DMP.ipynb
  - Steps Review & Findings: In the notebook
  - Status: SUCCESFUL

