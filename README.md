# HuggingFace, LoRA with Distributed SageMaker

## MAIN OBJECTIVE:
- To test DISTRIBUTED implementation of LoRA traiing of HiggingFace's LLM models with Distributed SageMaker
  - Notebook: sagemaker-notebook-LORA.ipynb SM
  - Findings: In the notebook
  - Status: SUCCESFUL 

## SECONDARY OBJECTIVE:
- To test Distributed Model Parallel Options @ AWS SageMaker
  - Notebook: SM Distributed Training - DDP & DMP.ipynb
  - Findings: In the notebook
  - Status: SUCCESFUL

